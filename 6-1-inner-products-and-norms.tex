\section{Inner Products and Norms} \label{sec 6.1}

Many geometric notions such as angle, length, and perpendicularity in \(\SET{R}^2\) and \(\SET{R}^3\) may be extended to more general real and complex vector spaces.
All of these ideas are related to the concept of \emph{inner product}.

\begin{definition} \label{def 6.1}
Let \(\V\) be a vector space over \(F\).
An \textbf{inner product} on \(\V\) is a \emph{function} that assigns, to every ordered pair of vectors \(x\) and \(y\) in \(\V\), a \textbf{scalar} in \(F\), denoted \(\LG x, y \RG\), such that for all \(x, y\), and \(z\) in \(\V\) and all \(c\) in \(F\), the following bold:
\begin{enumerate}
\item \(\LG x + z, y \RG = \LG x, y \RG + \LG z, y \RG\).
\item \(\LG cx, y \RG = c \LG x, y \RG\).
\item \(\conjugatet{\LG x, y \RG} = \LG y, x \RG\), where the bar denotes complex conjugation.
\item If \(x \ne \OV\), then \(\LG x, x \RG\) is a positive real number.
\end{enumerate}
\end{definition}

\begin{note}
(d) 意思是連虛部都不能有
只能是個純實數 還要是正的
\end{note}

\begin{remark} \label{remark 6.1.1}
Remember the assumption in the beginning of the chapter that we assume \(F\) to be either \(\SET{C}\) or \(\SET{R}\).
Note that (c) reduces to \(\LG x, y \RG = \LG y, x \RG\) if \(F = \SET{R}\).
Conditions (a) and (b) simply require that the inner product \emph{be linear in the first component}.

It is easily shown that if \(a_1, a_2, ..., a_n \in F\) and \(y, v_1, v_2, ..., v_n \in V\), then (by induction and (a)(b))
\[
    \LG \sum_{i = 1}^n a_i v_i, y \RG = \sum_{i = 1}^n a_i \left< v_i, y \right>
\]
\end{remark}

\begin{example} \label{example 6.1.1}
For \(x = (a_1, a_2, ..., a_n)\) and \(y = (b_1, b_2, ..., b_n)\) in \(F^n\), define
\[
    \LG x, y \RG = \sum_{i = 1}^n a_i \conjugatet{b_i}.
\]
The verification that \(\LG< \cdot, \cdot \RG\) satisfies conditions \DEF{6.1}(a) through (d) is easy.
For example, if \(z = (c_1, c_2, ..., c_n)\), we have for (a)
\begin{align*}
    \LG x + z, y \RG & = \sum_{i = 1}^n (a_i + c_i) \conjugatet{b_i} & \text{by def of the operation} \\
    & = \sum_{i = 1}^n a_i \conjugatet{b_i} + \sum_{i = 1}^n c_i \conjugatet{b_i} & \text{by distributivity of field} \\
    & = \LG x, y \RG + \LG z, y \RG.
\end{align*}
Thus, for \(x = (1 + \iu, 4)\) and \(y = (2 - 3\iu, 4 + 5\iu)\) in \(\SET{C}^2\),
\[
    \LG x, y \RG = (1 + \iu)\conjugatet{(2 - 3\iu)} + 4\conjugatet{(4 + 5\iu)} = (1 + \iu)(2 + 3\iu) + 4(4 - 5\iu) = 15 - 15\iu.
\]
\end{example}

\begin{remark} \label{remark 6.1.2}
The inner product in \EXAMPLE{6.1.1} is called the \textbf{standard inner product} on \(F^1\).
When \(F = \SET{R}\), the conjugations are \emph{not needed}, and in early courses this standard inner product is usually called the \textbf{dot product} and is denoted by \(x \cdot y\) instead of \(\LG x,y \RG\).
\end{remark}

\begin{example} \label{example 6.1.2}
If \(\LG x, y \RG\) is any inner product on a vector space \(V\) and \(r > 0\), we may define \emph{another} inner product by the rule \(\LG x, y \RG' = r \LG x, y \RG\).
If \(r \le 0\), then \DEF{6.1}(d) would \emph{not} hold.
\end{example}

\begin{example} \label{example 6.1.3}
Let \(\V = \CONT([0, 1])\), the vector space of \emph{real-valued continuous functions} on \([0, 1]\).
For \(f, g \in V\), define \(\LG f, g \RG = \int_0^1 f(t)g(t) dt\).
Since the preceding \emph{integral is linear} in \(f\), \DEF{6.1}(a) and (b) are immediate, and (c) is trivial.
(Again note that in this context (c) is only \(\LG f, g \RG = \LG g, f \RG\), and it's of course true since \(\int_0^1 f(t)g(t) dt = \int_0^1 g(t)f(t) dt\).)
If \(f \ne 0\), then \(f^2\) is \textbf{bounded away from zero} on some \emph{subinterval} of \([0, 1]\) (\emph{continuity} is used here; refer to Calculus or Analysis course), and hence \(\LG f, f \RG = \int_0^1 [f(t)]^2 dt > 0\).
\end{example}

\begin{definition} \label{def 6.2}
Let \(A \in M_{m \X n}(F)\).
We define the \textbf{conjugate transpose} or \textbf{adjoint} of \(A\) to be the \(n \X m\) matrix \(A^*\) such that \((A^*)_{ij} = \conjugatet{A_{ji}}\) for all \(i, j\).

(Also see \ADEF{4.4} and the corresponding exercises.)
\end{definition}

\begin{example} \label{example 6.1.4}
Let
\[
    A = \begin{pmatrix} \iu & 1 + 2\iu \\ 2 & 3 + 4\iu \end{pmatrix}.
\]
Then
\[
    A^* = \begin{pmatrix} -\iu & 2 \\ 1 - 2\iu & 3 - 4\iu \end{pmatrix}.
\]
\end{example}

\begin{remark} \label{remark 6.1.3}
(\RED{Warning}: the text below is in the textbook before \EXAMPLE{6.1.5}.
But I really do not know whether it's a definition or a convention or something else.)

Notice that if \(x\) and \(y\) are viewed as column vectors in \(F^n\), then (we define? we often treat it conventionally? or what?) \(\LG x, y \RG = y^* x\).
\end{remark}

\begin{remark} \label{remark 6.1.4}
The conjugate transpose of a matrix plays a \emph{very important role} in the remainder of this chapter. In the case that \(A\) has real entries, \emph{\(A^*\) is simply the transpose of \(A\)}.
\end{remark}

\begin{example} \label{example 6.1.5}
Let \(\V = M_{n \X n}(F)\), and define \(\LG A, B \RG = \TRACE(B^* A)\) for \(A, B \in V\).
(Recall that the trace of a matrix \(A\) is defined by \(\TRACE(A) = \sum_{i = 1}^n A_{ii}\).)
We verify that (a) and (d) of the definition of inner product hold and leave (b) and (c) to the reader. For this purpose, let \(A, B, C \in V\).
Then (using \EXEC{1.3.6})
\begin{align*}
    \LG A + B, C \RG & = \TRACE(C^* (A + B)) & \text{by def of the operation} \\
        & = \TRACE(C^* A + C^* B) & \text{by \THM{2.12}(a)} \\
        & = \TRACE(C^* A) + \TRACE(C^* B) & \text{by \EXEC{1.3.6}} \\
        & = \LG A, C \RG + \LG B, C \RG & \text{by def of the operation}
\end{align*}
Also
\begin{align*}
    \LG A, A \RG & = \TRACE(A^* A) & \text{by def of the operation} \\
        & = \sum_{i = 1}^n (A^* A)_{ii} & \text{by def of trace} \\
        & = \sum_{i = 1}^n \sum_{k = 1}^n (A^*)_{ik} A_{ki} & \text{by def of matrix multiplication} \\
        & = \sum_{i = 1}^n \sum_{k = 1}^n \RED{\conjugatet{A}_{ki}} A_{ki} & \text{by \DEF{6.2}} \\
        & = \sum_{i = 1}^n \sum_{k = 1}^n \abs{A_{ki}}^2 & \text{by \DEF{d.3}}
\end{align*}
Now if \(A \ne O\), the zero vector of \(M_{n \X n}\), then \(A_{ki} \ne 0\) for some \(k\) and \(i\) hence \(\abs{A_{ki}}^2 > 0\).
So \(\LG A, A \RG > 0\).
\end{example}

\begin{remark} \label{remark 6.1.5}
In fact we can see the Frobenius inner product as a component-wise inner product of two matrices \(A, B\) as though they are vectors, but taking conjugate for \(B\)'s components.
That is,
\[
    \LG A, B \RG = \sum_{i, j} A_{ij} \conjugatet{B_{ij}}.
\]
\end{remark}

\begin{additional definition} \label{adef 6.1}
The inner product on \(M_{n \X n}(F)\) in \EXAMPLE{5.1.5} is called the \textbf{Frobenius inner product}.
\end{additional definition}

\begin{remark} \label{remark 6.1.6}
A vector space \(\V\) over \(F\) endowed with a specific inner product is called an \textbf{inner product space}.
(Again by the assumption in the beginning of the chapter that we assume \(F\) to be either \(\SET{C}\) or \(\SET{R}\).)
If \(F = \SET{C}\), we call \(V\) a \textbf{complex inner product space}, whereas if \(F = \SET{R}\), we call \(V\) a \textbf{real inner product space}.

Thus \EXAMPLE{6.1.1}, \EXAMPLE{6.1.3}, and \EXAMPLE{6.1.5} also provide examples of inner product spaces.
\begin{center}\emph{
    For the remainder of this chapter, \(F^n\) denotes the inner product space \emph{with the standard inner product} as defined in \EXAMPLE{6.1.1}.
Likewise, \(M_{n \X n}(F)\) denotes the inner product space with the Frobenius inner product as defined in \EXAMPLE{5.1.5}.
}\end{center}
\end{remark}

\begin{remark} \label{remark 6.1.7}
The reader is cautioned that \emph{two distinct inner products on a given vector space yield two distinct inner product spaces}.
For instance, it can be shown that both
\[
    \LG f(x), g(x) \RG_1 = \int_0^1 f(t) g(t) d t
    \quad \text { and } \quad
    \LG f(x), g(x) \RG_{2} = \int_{\RED{-1}}^{1} f(t) g(t) d t
\]
are inner products on the vector space \(\POLYRINF\).
Even though the underlying vector space is the same, however, these two inner products yield two different inner product spaces.
For example, the polynomials \(f(x) = x\) and \(g(x) = x^2\) are \emph{orthogonal}(see \DEF{6.4}) in the second inner product space, but not in the first.
\end{remark}

\begin{remark} \label{remark 6.1.8}
A very important inner product space that resembles \(\CONT([O, 1])\) is the space \(\textsf{H}\) of continuous \textbf{complex}-valued functions defined on the interval \([0, 2\pi]\) with the inner product
\[
    \LG f, g \RG = \frac{1}{2\pi} \int_0^{2\pi} f(t) \conjugatet{g(t)} dt.
\]
The reason for the constant \(1/2\pi\) will become evident later.
This inner product space, which arises often \emph{in the context of physical situations}, is examined
more closely in later sections.

At this point, we mention a few facts about integration of complex-valued functions.
First, the imaginary number \(\iu\) can be treated as a constant under the integration sign.
Second, every complex-valued function \(f\) may be written as \(f = f_1 + i f_2\), where \(f_i\) and \(f_2\) are real-valued functions.
Thus we have
\[
    \int f dt = \int f_1 dt + \iu f_2 dt \quad \text{ and } \quad \conjugatet{\int f} dt = \int \conjugatet{f} dt
\]
From these properties, as well as the assumption of continuity, it follows that \(\textsf{H}\) is an inner product space (see \EXEC{6.1.16}(a)).
\end{remark}

\begin{theorem} \label{thm 6.1}
Let \(\V\) be an inner product space.
Then for \(x, y, z \in \V\) and \(c \in F\), the following statements are true.
\begin{enumerate}
\item \(\LG x, y + z \RG = \LG x, y \RG + \LG x, z \RG\).
\item \(\LG x, cy \RG = \conjugatet{c} \LG x, y \RG\).
\item \(\LG x, \OV \RG = \LG \OV, x \RG = 0\).
\item \(\LG x, x \RG = 0\) if and only if \(x = \OV\).
\item If \(\LG x, y \RG = \LG x, z \RG\) \emph{for all} \(x \in \V\), then \(y = z\).
\end{enumerate}
\end{theorem}

\begin{note}
A particular consequence of (e) is \EXEC{6.1.1}(h), which is a way to check whether a given vector is zero vector.
\end{note}

\begin{proof} \ 

\begin{enumerate}
\item We have
\begin{align*}
    \LG x, y + z \RG & = \conjugatet{\LG y + z, x \RG} & \text{by \DEF{6.1}(c)} \\
        & = \conjugatet{\LG y, x \RG + \LG z, x \RG} & \text{by \DEF{6.1}(a)} \\
        & = \conjugatet{\LG y, x \RG} + \conjugatet{\LG z, x \RG} & \text{by \THM{d.2}(b)} \\
        & = \LG x, y \RG + \LG x, z \RG & \text{by \DEF{6.1}(c)}
\end{align*}

\item We have
\begin{align*}
    \LG x, cy \RG & = \conjugatet{\LG cy, x \RG} & \text{by \DEF{6.1}(c)} \\
        & = \conjugatet{c \LG y, x \RG} & \text{by \DEF{6.1}(b)} \\
        & = \conjugatet{c} \conjugatet{\LG y, x \RG} & \text{by \THM{d.2}(c)} \\
        & = \conjugatet{c} \LG x, y \RG & \text{by \DEF{6.1}(c)}
\end{align*}

\item We have
\begin{align*}
    \LG x, \OV \RG & = \LG x, -1 \cdot \OV \RG & \text{since \(\OV = -1 \cdot \OV\)} \\
        & = \conjugatet{-1} \LG x, \OV \RG & \text{by part(b)} \\
        & = -1 \LG x, \OV \RG & \text{of course} \\
    \implies & 2 \LG x, \OV \RG = 0 \\
    \implies & \LG x, \OV \RG = 0 & \text{since \(F = \SET{C}\) have characteristic zero}
\end{align*}
Similarly,
\begin{align*}
    \LG \OV, x \RG & = \LG -1 \OV, x \RG & \text{since \(\OV = -1\OV\)} \\
        & = -1 \LG x, \OV \RG & \text{by \THM{6.1}(b)} \\
    \implies & 2 \LG x, \OV \RG = 0 \\
    \implies & \LG x, \OV \RG = 0 & \text{since \(F = \SET{C}\) have characteristic zero}
\end{align*}

\item
\(\Longrightarrow\): Suppose \(\LG x, x \RG = 0\) but \(x \ne \OV\), but by \DEF{6.1}(d), \(\LG x, x \RG\) will be a positive real number, which is not zero, a contradiction.
Hence \(x = \OV\).

\(\Longleftarrow\): Suppose \(x = \OV\).
Then in particular by part(d), \(\LG x, x \RG = \LG x, \OV \RG = 0\).

\item Suppose \(\LG x, y \RG = \LG x, z \RG\) for all \(x \in \V\).
Then for any \(x \in \V\),
\begin{align*}
             & \LG x, y \RG = \LG x, z \RG \\
    \implies & \LG x, y \RG + (-1) \LG x, z \RG = 0 & \text{of course} \\
    \implies & \LG x, y \RG + \LG x, \conjugatet{(-1)} z \RG = 0 & \text{by part(b)} \\
    \implies & \LG x, y \RG + \LG x, (-1) z \RG = 0 & \text{of course} \\
    \implies & \LG x, y - z \RG = 0 \quad \MAROON{(1)} & \text{by part(a)} \\
\end{align*}
Now we just let \(x = y - z\), then from \MAROON{(1)} we have \(\LG x, y - z \RG = \LG y - z, y - z \RG = 0\).
Then by part(d), \(y - z = \OV\), hence \(y = z\).
\end{enumerate}
\end{proof}

\begin{remark} \label{remark 6.1.9}
The reader should observe that (a) and (b) of \THM{6.1} show that the inner product is \textbf{conjugate linear} in the \emph{second} component.
That is, for any inner product space \(\V\) and \(v, w_1, w_2 \in \V\) and scalar \(c \in F\),
\[
    \LG v, c w_1 + w_2 \RG = \RED{\conjugatet{c}} \LG v, w_1 \RG + \LG v, w_2 \RG.
\]
\end{remark}

In order to generalize the notion of \textbf{length} in \(\SET{R}^3\) to arbitrary inner product spaces, we need only observe that the length of \(x = (a, b, c) \in \SET{R}^3\) is (conventionally) given by (the Euclidean distance) \( \sqrt{a^2 + b^2 + c^2} \), which is equal to \(\sqrt{\LG x, x\RG}\) (where we use the standard inner product here).
This leads to the following definition.

\begin{definition} \label{def 6.3}
Let \(\V\) be an inner product space.
For \(x \in \V\), we define the \textbf{norm} or \textbf{length} of \(x\) by \(\norm{x} = \sqrt{\LG x, x \RG}\).
\end{definition}

\begin{example} \label{example 6.1.6}
Let \(\V = F^n\).
(Hence we use the standard inner product.)
If \(x = (a_1, a_2, ..., a_n)\), then
\[
    \norm{x} = \norm{(a_1, a_2, ..., a_n)} = \left[ \sum_{i = 1}^n \abs{a_n}^2 \right]^{1/2}
\]
\emph{is} the Euclidean definition of length.
Note that if \(n = 1\), we have \(\norm{a} = \abs{a}\).
\end{example}

As we might expect, the well-known properties of Euclidean length in \(\SET{R}^3\) \emph{hold in general}, as shown next.

\begin{theorem} \label{thm 6.2}
Let \(\V\) be an inner product space over \(F\).
Then for all \(x, y \in \V\) and \(c \in F\), the following statements are true.
\begin{enumerate}
\item \(\norm{c \cdot x} = \abs{c} \cdot \norm{x}\).
\item \(\norm{x} = 0\) if and only if \(x = \OV\).
In any case, \(\norm{x} \ge 0\).
\item (Caucby-Schwarz Inequality) \(\abs{\LG x, y \RG} \le \norm{x} \cdot \norm{y}\).
\item (Triangle Inequality) \(\norm{x + y} \le \norm{x} + \norm{y}\).
\end{enumerate}
\end{theorem}

\begin{proof} \ 

\begin{enumerate}
\item We have
\begin{align*}
    \norm{c \cdot x} & = \sqrt{\LG c \cdot x, c \cdot x \RG} & \text{by \DEF{6.3}} \\
        & = \sqrt{c \LG x, c \cdot x \RG} & \text{by \DEF{6.1}(b)} \\
        & = \sqrt{c \conjugatet{c} \LG x, x \RG} & \text{by \THM{6.1}(b)} \\
        & = \sqrt{\abs{c}^2 \LG x, x \RG} & \text{by \RMK{d.5}} \\
        & = \abs{c} \sqrt{\LG x, x \RG} & \text{of course by complex field algebra} \\
        & = \abs{c} \norm{x} & \text{by \DEF{6.3}}
\end{align*}

\item We have
\begin{align*}
         & \norm{x} = 0 \\
    \iff & \sqrt{\LG x, x \RG} = 0 & \text{by \DEF{6.3}} \\
    \iff & \LG x, x \RG = 0^2 = 0 & \text{of course} \\
    \iff & x = \OV & \text{by \THM{6.1}(d)}
\end{align*}

\item We have to show \(\abs{\LG x, y \RG} \le \norm{x} \cdot \norm{y}\).
If \(y = \OV\), then by part(b), \(\norm{y} = 0\), hence the right side of the equation is \(\norm{x} \cdot \norm{y} = \norm{x} \cdot 0 = 0\);
And \(\LG x, y \RG = \LG x, \OV \RG = 0\) by \THM{6.1}(c), hence the left side of the equation is \(\abs{\LG x, y \RG} = \abs{0} = 0\).
So the equation holds when \(y = \OV\).

Now assume that \(y \ne \OV\).
For any \(c \in F\), we have
\begin{align*}
    0 & \le \LG x - cy, x - cy \RG & \text{by \DEF{6.1}(d)} \\
      & = \LG x, x - cy \RG - c \LG y, x - cy \RG & \text{linear in the first component} \\
      & = \LG x, x \RG - \conjugatet{c} \LG x, y \RG - c \LG y, x \RG - c \cdot \conjugatet{(-c)} \LG y, y \RG & \text{\emph{conjugate linear} in the second component} \\
      & = \LG x, x \RG - \conjugatet{c} \LG x, y \RG - c \LG y, x \RG + c \cdot \conjugatet{c} \LG y, y \RG & \text{of course}
\end{align*}
In particular, if we set
\[
    c = \frac{\LG x, y \RG}{\LG y, y \RG},
\]
then each of \(\conjugatet{c} \LG x, y \RG, c \LG y, x \RG\), and \(c \cdot \conjugatet{c} \LG y, y \RG\) equals
\[
    \frac{\LG x, y \RG \LG y, x \RG}{\LG y, y \RG}
    = \frac{\LG x, y \RG \conjugatet{\LG x, y \RG}}{\norm{y}^2}
    = \frac{\abs{ \LG x, y \RG }^2}{\norm{y}^2}
\]
So the preceding inequality becomes
\begin{align*}
    0 & \le \LG x, x \RG - \conjugatet{c} \LG x, y \RG - c \LG y, x \RG + c \cdot \conjugatet{c} \LG y, y \RG \\
      & = \LG x, x \RG - \frac{\abs{ \LG x, y \RG }^2}{\norm{y}^2} - \frac{\abs{ \LG x, y \RG }^2}{\norm{y}^2} + \frac{\abs{ \LG x, y \RG }^2}{\norm{y}^2} \\
      & = \LG x, x \RG - \frac{\abs{ \LG x, y \RG }^2}{\norm{y}^2} \\
      & = \norm{x}^2 - \frac{\abs{ \LG x, y \RG }^2}{\norm{y}^2},
\end{align*}
which implies \(\abs{ \LG x, y \RG }^2 \le \norm{x}^2 \cdot \norm{y}^2\), which implies (c) by taking square root, as desired.

\item We have
\begin{align*}
    \norm{x + y}^2 & = \LG x + y, x + y \RG & \text{by \DEF{6.3}} \\
        & = \LG x, x + y \RG + \LG y, x + y \RG & \text{by \DEF{6.1}(a)} \\
        & = \LG x, x \RG + \LG x, y \RG + \LG y, x \RG + \LG y, y \RG & \text{by \THM{6.1}(a)} \\
        & = \norm{x}^2 + \LG x, y \RG + \LG y, x \RG + \norm{y}^2 & \text{by \DEF{6.3}} \\
        & = \norm{x}^2 + \LG x, y \RG + \conjugatet{\LG x, y \RG} + \norm{y}^2 & \text{by \DEF{6.1}(c)} \\
        & \RED{*}= \norm{x}^2 + 2 \cdot \mathcal{R}\LG x, y \RG + \norm{y}^2 \\
        & \le \norm{x}^2 + 2 \cdot \left| \LG x, y \RG \right| + \norm{y}^2 \\
        & \le \norm{x}^2 + 2 \cdot \norm{x} \norm{y} + \norm{y}^2 & \text{by part(c)} \\
        & = \left(\norm{x} + \norm{y}\right)^2,
\end{align*}
\RED{*}where \(\mathcal{R}\LG x, y \RG\) denotes the \emph{real part} of the complex number \(\LG x, y \RG\), and hence \(\mathcal{R}\LG x, y \RG \le \left| \LG x, y \RG \right|\).
(Let \(\LG x, y \RG = a + b \iu\), then \(\mathcal{R}\LG x, y \RG = a \le \sqrt{a^2 + b^2} = \abs{a + b\iu} = \abs{\LG x, y \RG}\).)
And taking square root of the inequality, we get (d).
\end{enumerate}

\begin{note}
The case when \emph{equality} results in (c) and (d) is considered in \EXEC{6.1.15}.
什麼時候成立?
你看 (c) 那個證明過程，都寫出 \(x - cy\) 這種東西了
成立的時候就是 \(x = cy\) 的時候。
阿 (d) 就是兩個向量垂直的時候ㄏㄏ。
\end{note}
\end{proof}

\begin{example} \label{example 6.1.7}
For \(F^n\), we may apply (c) and (d) of \THM{6.2} to the \emph{standard inner product} to obtain the following \emph{well-known inequalities};
That is, given \(a = (a_1, ..., a_n), b = (b_1, ..., b_n) \in F^n\), we have
\begin{align*}
    \left| \sum_{i = 1}^n a_i \conjugatet{b_i} \right|
        & = \left| \LG a, b \RG \right| & \text{by def of std inner prod.} \\
        & \RED{\le} \norm{a} \cdot \norm{y} & \text{by \THM{6.1}(c)} \\
        & = \left[ \sum_{i = 1}^n a_i\conjugatet{a_i} \right]^{1/2} + \left[ \sum_{i = 1}^n b_i\conjugatet{b_i} \right]^{1/2} & \text{by \DEF{6.1} and std inner prod.} \\
        & = \left[ \sum_{i = 1}^n \abs{a_i}^2 \right]^{1/2} + \left[ \sum_{i = 1}^n \abs{b_i}^2 \right]^{1/2} & \text{by \RMK{d.5}}
\end{align*}
Similarly, by \THM{6.2}(d) and the def of standard inner product,
\[
    \left[ \sum_{i = 1}^n \abs{a_i + b_i}^2 \right]^{1/2} \le \left[ \sum_{i = 1}^n \abs{a_i}^2 \right]^{1/2} + \left[ \sum_{i = 1}^n \abs{b_i}^2 \right]^{1/2}.
\]
\end{example}

\begin{note}
上一個例子內推出柯西不等式的意義是，\THM{6.2}(c) 在任何內積空間都對，但是如果我們把任兩串 \(n\) 個數字 \(a_i\) 跟 \(b_i\) 看成是 \(F^n\) 的向量，並且使用標準內積，則配合 \THM{6.2}(c) 後的結果，就會是柯西不等式。

當然我們也可直接從實數或複數的定義推出柯西不等式，可參考分析課本。
\end{note}

The reader may recall from earlier courses that, for \(x\) and \(y\) in \(\SET{R}^3\) or \(\SET{R}^2\), we have that \(\LG x, y \RG = \norm{x} \cdot \norm{y} \cos \theta\), where \(\theta (0 \le \theta \le \pi)\) denotes the \emph{angle} between \(x\) and \(y\).
This equation implies \THM{6.2}(c) immediately since \(\abs{ \cos \theta } \le 1\).
Notice also that nonzero vectors \(x\) and \(y\) are \emph{perpendicular} if and only if \(\cos \theta = 0\), that is, if and only if \(\LG x, y \RG = 0\).
We are now at the point where we can \textbf{generalize the notion of perpendicularity} to arbitrary inner product spaces.

\begin{definition} \label{def 6.4}
Let \(\V\) be an inner product space.

\BLUE{(1)} Vectors \(x\) and \(y\) in \(\V\) are \textbf{orthogonal} (or \textbf{perpendicular}) if \(\LG x, y \RG = 0\).

\BLUE{(2)} A subset \(S\) of \(\V\) is \textbf{orthogonal} if any two distinct vectors in \(S\) are orthogonal.

\BLUE{(3)} A vector \(x\) in \(\V\) is a \textbf{unit vector} if \(\norm{x} = 1\).

\BLUE{(4)} Finally, a subset \(S\) of \(\V\) is \textbf{ortho\RED{normal}} if \(S\) is orthogonal \emph{and} consists entirely of unit vectors.

Note that we never assume \(\V\) to be finite-dimensional.

And note that if \(S = \{ v_1, v_2, ... \}\), then \(S\) is orthonormal if and only if \(\LG v_i, v_i \RG = \delta_{ij}\), where \(\delta_{ij}\) denotes the Kronecker delta.
Also, observe that multiplying vectors by \emph{nonzero} scalars does not affect their orthogonality and that if \(x\) is any nonzero vector, then \(\cfrac{1}{\norm{x}} x\) is a unit vector.
The process of multiplying a nonzero vector by the reciprocal of its length is called \textbf{normalizing}.

\end{definition}

\begin{example} \label{example 6.1.8}
In \(F^3\) (with standard inner product), \(\{ (1, 1, 0), (1, -1, 1), (-1, 1, 2) \}\) is an orthogonal set of nonzero vectors, but it is \emph{not} orthonormal;
however, if we \emph{normalize} the vectors in the set, we obtain the orthonormal set
\[
    \left\{ \frac{1}{\sqrt{2}}(1, 1, 0), \frac{1}{\sqrt{3}}(1, -1, 1), \frac{1}{\sqrt{6}}(-1, 1, 2) \right\}
\]
\end{example}

Our next example is of an \textbf{\emph{infinite} orthonormal set} that is \emph{important in (real and complex) analysis}.
This set is used in later examples in this chapter.

\begin{example} \label{example 6.1.9}
Recall the inner product space \(\textsf{H}\) (defined in \RMK{6.1.8}).
We introduce an important orthonormal subset \(S\) of \(\textsf{H}\).
For what follows, \(\iu\) is the imaginary number such that \(\iu^2 = -1\).
For any integer \(n\), let \(f_n(t) = e^{\iu n t}\), where \(0 \le t \le 2 \pi\).
(Recall that \(e^{\iu nt} = \cos nt + \iu \sin nt\). \MAROON{(1)})
左邊 = cont{cos (i t) + i sin(it)}
= cost(i t) - i sin(it)
= cost(-it) - i sin(it) // cos 偶函數
= cos(-it) - (-i sin(-it)) // sin 奇函數
= cost(-it) + i sin(-it)
= 右邊)
Now define \(S = \{ f_n : n \text{ is an integer} \}\).
Clearly \(S\) is a subset of \(H\).
Using the property that \(\conjugatet{e^{\iu t}} = e^{-\iu t}\) \MAROON{(2)} for every real number \(t\), we have, for \(m \ne n\),
\begin{align*}
    \LG f_m, f_n \RG & = \frac{1}{2\pi} \int_0^{2\pi} e^{\iu m t} \conjugatet{e^{\iu n t}} dt & \text{by def of inner prod. for \(\textsf{H}\)} \\
        & = \frac{1}{2\pi} \int_0^{2\pi} e^{\iu m t} e^{-\iu n t} dt & \text{by \MAROON{(2)}} \\
        & = \frac{1}{2\pi} \int_0^{2\pi} e^{\iu (m - n) t} dt & \text{by exponential algebra} \\
        & = \frac{1}{2\pi \iu(m - n)} \left[ e^{\iu(m - n)t} \Big|_0^{2\pi} \right] & \text{by (complex) Calculus} \\
        & = \frac{1}{2\pi \iu(m - n)} \left[ e^{\iu(m - n)2\pi} - e^0 \right] \\
        & = \frac{1}{2\pi \iu(m - n)} \left[ \cos[(m - n)2\pi] + \iu \sin[(m - n)2\pi] - e^0 \right] & \text{by \MAROON{(1)}} \\
        & = \frac{1}{2\pi \iu(m - n)} \left[ 1 + 0 - 1 \right] & \text{of course} \\
        & = \frac{1}{2\pi \iu(m - n)} \cdot 0 = 0.
\end{align*}
Also using similar derivation,
\[
    \LG f_n, f_n \RG = \frac{1}{2\pi} \int_0^{2\pi} e^{\iu(n - n)t} dt = \frac{1}{2\pi} \int_0^{2\pi} 1 dt = 1. 
\]
In other words, \(\LG f_m, f_n \RG = \delta_{mn}\).
\end{example}