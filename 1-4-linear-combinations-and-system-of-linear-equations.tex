\section{Linear Combinations and System of Linear Equations} \label{sec 1.4}

\begin{definition} \label{def 1.3}
Let \(V\) be a vector space (over \(F\)) and \(S\) a nonempty \emph{subset}(not necessarily subspace) of \(V\).
A vector \(v \in V\) is called a \textbf{linear combination} of vectors \emph{of \(S\)} if there exist a \emph{finite} number of vectors \(u_1, u_2, ..., u_n \in S\) and scalars \(a_1, a_2, ..., a_n \in F\) such that \(v = a_1 u_1 + a_2 u_2 + ... + a_n u_n\).
In this case we also say that \(v\) is a linear combination of \(u_1, u_2, ..., u_n\) and call \(a_1, a_2, ..., a_n\) the \textbf{coefficients}
of the linear combination.
\end{definition}

\begin{note}
Observe that in any vector space \(V\), \(0v = \OV\) (by \THM{1.2}(a)) for each \(v \in V\).
Thus the zero vector is a linear combination of any \emph{nonempty} subset of \(V\).
\end{note}

\begin{example}
Trivial.
\end{example}

Throughout \CH{1} and \CH{2} we encounter many different situations in which it is necessary to determine \emph{whether or not a vector can be expressed as a linear combination of} other vectors, and if so, how. 
This question often \textbf{reduces to the problem of solving a system of linear equations}.
In \CH{3}, we discuss a general method for using matrices to solve any system of linear equations.

\begin{remark} \label{remark 1.4.1}
We can solve system of linear equations by using the following three operations:
\begin{enumerate}
    \item interchanging the order of any two equations in the system; 
    \item multiplying any equation in the system by a \emph{nonzero} constant;
    \item adding a constant multiple of any equation to another equation in the system.
\end{enumerate}
In \SEC{3.3}, \SEC{3.4}, we will see that the system after applying these operations still have the same solutions set as the original system.
And these operations are called \textbf{elementary row operations}。

Note that we employed these operations \emph{until} the resulting system of equations have the following properties:
\begin{enumerate}
\item The first nonzero coefficient in each equation is one.
\item If an unknown is the first unknown with a nonzero coefficient in some equation, then that unknown occurs with a zero coefficient in each of the other equations.
\item The first unknown with a nonzero coefficient in any equation \emph{has a larger subscript} than the first unknown with a nonzero coefficient in any preceding equation.

Once a system with properties 1, 2, and 3 has been obtained, it is easy to solve for some of the unknowns in terms of the others.
If, however, in the course of using operations 1, 2, and 3 a system containing an equation of the form \(0 = c\), where \(c\) is nonzero, is obtained, then the original system \emph{has no solutions}.
\end{enumerate}
\end{remark}

\begin{note}
我們會用那三個\ operations 將\ system of equation 整理到有下列三個特性:
\begin{enumerate}
\item 每一條\ equation 的「第一個」未知數的係數是\ 1。
\item 對於每一條\ equation 的「第一個」係數非零的未知數，其他條\ equations 的這個未知數的係數必須是\ 0。
\item 每一條\ equation 的「第一個未知數」的「位置」要比所有這條\ equation 前面的\ equations 的第一個未知數的位置都還要後面。
\end{enumerate}
\end{note}

\begin{example} \label{example 1.4.2}
We claim that
\[
    2x^3 - 2x^2 + 12x - 6
\]
is a linear combination of
\[
    x^3 - 2x^2 - 5x - 3 \text{ and } 3x^3 - 5x^2 - 4x - 9
\]
in \(\mathcal{P}_3(\SET{R})\), but that
\[
    3x^3 - 2x^2 + 7x + 8
\]
is not.
In the first case we wish to find scalars \(a\) and \(b\) such that
\begin{align*}
    2x^3 - 2x^2 + 12x - 6 = a(x^3 - 2x^2 - 5^x - 3) + b(3x^3 - 5x^2 - 4x - 9) \\
    = (a + 3b)x^3 + (-2a - 5b)x^2 + (-5a - 4b)x + (-3a - 9b).
\end{align*}
Thus we are led to the following system of linear equations:
\begin{equation*}
\sysdelim..\systeme{
      a + 3b = 2,
    -2a - 5b = -2,
    -5a - 4b = 12,
    -3a - 9b = -6.}
\end{equation*}
Simplifying, we have
\begin{align*}
    a & = -4 \\
    b & = 2 \\
    0 & = 0 \\
    0 & = 0
\end{align*}
Hence
\[
    2x^3 - 2x^2 + 12x - 6 = -4(x^3 - 2x^2 - 5x - 3) + 2(3x^3 - 5x^2 - 4x - 9).
\]
(And skip second case.)
\end{example}

\begin{definition} \label{def 1.4}
Let \(S\) be a nonempty subset of a vector space \(V\).
The \textbf{span} of \(S\), denoted \(\spann(S)\), is the set consisting of all linear combinations of the vectors in \(S\).
For convenience, we \emph{define} \(\spann(\emptyset) = \{ \OV \}\).
\end{definition}

In \(\SET{R}^3\), for instance, the span of the set \(\{ (1,0,0), (0, 1,0) \}\) consists of all vectors in \(\SET{R}^3\) that have the form \(a(1, 0, 0) + b(O, 1, O) = (a, b, 0)\) for some scalars \(a\) and \(b\).
Thus the span of \(\{ (1, 0, 0), (0, 1, 0) \}\) contains all the points in the \(xy\)-plane.
In this case, the span of the set \emph{is a subspace} of \(\SET{R}^3\). This fact is \emph{true in general}.

\begin{theorem} \label{thm 1.5}\ 

\BLUE{(1)} The span of \emph{any} subset \(S\) of a vector space \(V\) is a \emph{subspace} of \(V\) that contains \(S\).

\BLUE{(2)} Moreover, any \emph{subspace} of \(V\) that contains \(S\) must also contain the span of \(S\).
\end{theorem}

\begin{note}
We say that \(\spann(S)\) is the ``smallest'' subspace that contains \(S\).

Also, it seems that we need to show \DEF{1.4} is well-defined.
But it is well-defined by \THM{1.5} since we know it is \emph{the smallest} subspace containing \(S\).
\end{note}

\begin{proof}
For \BLUE{(1)} there are two cases: \(S = \emptyset\) or not.
IF \(S\) is empty, then by \DEF{1.4}, \(\spann(S) = \{ \OV \}\), which is a subspace of \(V\).
If \(S\) is not empty, then we can pick a vector \(z\) in \(S\).
Furthermore, by \DEF{1.4}, the linear combination \(0z\) is in \(\spann(S)\), that is, \(\OV \in S\).
Suppose \(x, y \in \spann(S)\).
By \DEF{1.4}, there exist vectors \(u_1, u_2, ..., u_m\), \(v_1, v_2, ..., v_n\) in \(S\) and scalars \(a_1, a_2, ..., a_m\), \(b_1, b_2, ..., b_n\) such that
\[
    x = a_1 u_1 + a_2 u_2 + ... + a_m u_m \text{ and } y = b_1 v_1 + b_2 v_2 + ... + b_n v_n.
\]
Then
\[
    x + y = a_1 u_1 + a_2 u_2 + ... + a_m u_m + b_1 v_1 + b_2 v_2 + ... + b_n v_n,
\]
which is a linear combination of the vector in \(S\), so \(x + y \in \spann(S)\).
And
\[
    cx = c(a_1 u_1 + a_2 u_2 + ... + a_m u_m) = (c a_1) u_1 + (c a_2) u_2 + ... + (c a_m) u_m,
\]
which is also a linear combination of the vector in \(S\), so \(cx \in \spann(S)\).
So by \THM{1.3}, \(\spann(S)\) is a subspace of \(V\).
Furthermore given arbitrary \(s \in S\), \(1s = s\) is a linear combination of vector(s) in \(S\), so by \DEF{1.4}, \(s \in \spann(S)\).
So since \(s\) is arbitrary, \(S \subseteq \spann(S)\).

Now we prove \BLUE{(2)}.
Let \(W\) be an arbitrary subspace that contains \(S\).
We have to show \(\spann(S) \subseteq W\).
So let \(w \in \spann(S)\).
Again by \DEF{1.4}, \(w = c_1 w_1 + c_2 w_2 + ... + c_k w_k\) for some vectors \(w_1, w_2, ..., w_k\) in \(S\) and some scalars \(c_1, c_2, ..., c_k\).
Since \(S \subseteq W\), we have \(w_1, w_2, ..., w_k \in W\).
Therefore \(w = c_1 w_1 + c_2 w_2 + ... + c_k w_k\) is in \(W\) by \EXEC{1.3.20}.
Because \(w\), an arbitrary vector in \(\spann(S)\), belongs to \(W\), it follows that \(\spann(S) \subseteq W\).
\end{proof}

\begin{definition} \label{def 1.5}
A subset \(S\) of a vector space \(V\) \textbf{generates} (or \textbf{spans}) \(V\) if \(\spann(S) = V\).
In this case, we also say that the vectors of \(S\) generate (or span) \(V\).
\end{definition}

\begin{example} \label{example 1.4.3}
The vectors \((1, 1. 0), (1, 0, 1)\), and \((0, 1, 1)\) generate \(\SET{R}^3\) since an arbitrary vector \((a_1, a_2, a_3)\) in \(\SET{R}^3\) is a linear combination of the three given vectors:
in fact, the scalars \(r, s\), and \(t\) for which \(r(1, 1, 0) + s(1, 0, 1) + t(O, 1, 1) = (a_1, a_2, a_3)\)
are
\[
    r = \frac1{2}(a_1 + a_2 - a_3), s = \frac1{2}(a_1 - a_2 + a_3), \text{ and } t = \frac1{2}(-a_1 + a_2 + a_3).
\]
\end{example}

\begin{example} \label{example 1.4.4}
The polynomials \(x^2 + 3x - 2, 2x^2 + 5x - 3\), and \(-x^2 - 4x + 4\) generate \(\mathcal{P}_2(\SET{R})\) since each of the three given polynomials belongs to \(\mathcal{P}_2(\SET{R})\)
and each polynomial \(ax^2 + b_x + c \in \mathcal{P}_2(\SET{R})\) is a linear combination of these three,
namely, \((-a + 5b + 3c)(x^2 + 3x - 2) + (4a - 2b - c)(2x^2 + 5x - 3) + (-a + b + c)(-x^2 - 4x + 4) = ax^2 + bx +c\). 
\end{example}

\begin{example} \label{example 1.4.5}
The matrices
\[
\begin{pmatrix}
  1 & 1 \\
  1 & 0
\end{pmatrix},
\begin{pmatrix}
  1 & 1 \\
  0 & 1
\end{pmatrix},
\begin{pmatrix}
  1 & 0 \\
  1 & 1
\end{pmatrix}, \text{ and }
\begin{pmatrix}
  0 & 1 \\
  1 & 1
\end{pmatrix}
\]
generate \(M_{2 \X 2}(\SET{R})\) since an arbitrary matrix \(A\) in \(M_{2 \X 2}(\SET{R})\) can be expressed as a linear combination of the four given matrices(skip, see textbook page 32).

On the other hand, the matrices
\[
\begin{pmatrix}
  \BLUE{1} &       0 \\
        0  & \BLUE{1}
\end{pmatrix},
\begin{pmatrix}
  \BLUE{1} &       1 \\
        0  & \BLUE{1}
\end{pmatrix}, \text{ and }
\begin{pmatrix}
  \BLUE{1} &       0 \\
        1  & \BLUE{1}
\end{pmatrix}
\]
do not generate \(M_{2 \X 2}(\SET{R})\) because each of these matrices has equal diagonal entries.
So any linear combination of these matrices has equal diagonal entries.
Hence not every \(2 \X 2\) matrix is a linear combination of these three matrices.
\end{example}

\begin{remark} \label{remark 1.4.2}
Usually there are many different subsets that generate a subspace \(W\). (See \EXEC{1.4.13}.)
It is natural to seek a subset of \(W\) that generates \(W\) and is \textbf{as small as possible}.
In the next section we explore the circumstances under which a vector can be removed from a generating set to obtain a smaller generating set.
\end{remark}

\exercisesection

\begin{exercise} \label{exercise 1.4.1}
Label the following statements as true or false.
\begin{enumerate}
\item The zero vector is a linear combination of any nonempty set of vectors.
\item The span of \(\emptyset\) is \(\emptyset\).
\item If \(S\) is a subset of a vector space \(V\), then \(\spann(S)\) equals the \emph{intersection of all} subspaces of \(V\) that contain \(S\).
\item In solving a system of linear equations, it is permissible to multiply an equation by \emph{any} constant.
\item In solving a system of linear equations, it is permissible to add any multiple of one equation to another.
\item Every system of linear equations has a solution. 
\end{enumerate}
\end{exercise}

\begin{proof}\ 

\begin{enumerate}
\item True, see the proof of \THM{1.5}(1).
\item False, by \DEF{1.3}, \(\spann(\emptyset) = \{ \OV \}\).
\item True.
      We show \(\spann(S) \subseteq \bigcap_{i = 0}^{\infty} W_i\) and \(\bigcap_{i = 0}^{\infty} W_i \subseteq \spann(S)\) where each \(W_i\) is a subspace of \(V\) that contains \(S\).
      
      \(\spann(S) \subseteq \bigcap_{i = 0}^{\infty} W_i\): By \THM{1.5}, every subspace that contains \(S\) must also contain \(\spann(S)\), which implies the intersection of \emph{all} subspaces that contain \(S\) contain \(\spann(S)\).
      
      \(\bigcap_{i = 0}^{\infty} W_i \subseteq \spann(S)\):
      In particular, we have \(\spann(S) = W_i\) for some \(i\), since \(\spann(S)\) is \emph{also} a subspace that contains \(S\).
      So if arbitrary \(x \in \bigcap_{i = 0}^{\infty} W_i\), where one of \(W_i = \spann(S)\), then by definition of intersection, \(x\) must also be in that \(W_i = \spann(S)\).
      Since \(x\) is arbitrary, \(\bigcap_{i = 0}^{\infty} W_i \subseteq \spann(S)\), as desired.
\item False, by \RMK{1.4.1}(b) we can only multiply an equation by \emph{nonzero} constant.
\item True, by \RMK{1.4.1}(c).
\item False!
\end{enumerate}
\end{proof}

\begin{exercise} \label{exercise 1.4.2}
Computational problem, skip.
\end{exercise}

\begin{exercise} \label{exercise 1.4.3}
Computational problem, skip.
\end{exercise}

\begin{exercise} \label{exercise 1.4.4}
Computational problem, skip.
\end{exercise}

\begin{exercise} \label{exercise 1.4.5}
Computational problem, skip.
\end{exercise}

\begin{note}
Note that \EXEC{1.4.3} to \EXEC{1.4.4} embedded the concept of \textbf{linear dependency}, see \DEF{1.6}.
\end{note}

\begin{exercise} \label{exercise 1.4.6}
Show that the vectors \((1, 1, 0), (1, 0, 1)\), and \((0, 1, 1)\) generate \(F^3\).
\end{exercise}

\begin{proof}
Given any \((a, b, c) \in F^3\), \((a, b, c)\) can be expressed as a linear combination
\[
    \frac{a + b - c}{2} (1, 1, 0) + \frac{a - b + c}{2} (1, 0, 1) + \frac{-a + b + c}{2} (0, 1, 1).
\]
Hence by \DEF{1.5}, \(\{(1, 1, 0), (1, 0, 1), (0, 1, 1)\}\) generates \(F^3\).

BTW, the \emph{symbol} \(1\) and \(0\) in these tuples are the multiplicative identity and additive identity of the field \(F\).
\end{proof}

\begin{exercise} \label{exercise 1.4.7}
In \(F^n\), let \(e_j\) denote the \emph{vector} whose \(j\)th coordinate is \(1\) and whose other coordinates are \(0\).
Prove that \(\{ e_1, e_2, ..., e_n \}\) generates \(F^n\).
\end{exercise}

\begin{proof}
Given any \((a_1, a_2, ..., a_n) \in F^n\), \((a_1, a_2, ..., a_n)\) can be expressed as a linear combination
\[
    a_1 e_1 + a_2 e_2 + ... + a_n e_n.
\]
Hence by \DEF{1.5}, \(\{ e_1, e_2, ..., e_n \}\) generates \(F^n\).
\end{proof}

\begin{exercise} \label{exercise 1.4.8}
Show that \(\mathcal{P}_n(F)\) is generated by \(\{ l, x, x^2, ..., x^n\}\).
\end{exercise}

\begin{proof}
Given any polynomial \(p(x) = a_n x^n + a_{n - 1} x^{n - 1} + ... + a_1 x + a_0\) in \(\mathcal{P}_n(F)\) (where \(a_i\) can be zero), \(p(x)\) can be expressed as a linear combination
\[
    a_n (x^n) + a_{n - 1} (x^{n - 1}) + ... + a_1 (x) + a_0 (1).
\]
Hence by \DEF{1.5}, \(\{ l, x, x^2, ..., x^n\}\) generates \(\mathcal{P}_n(F)\).
\end{proof}

\begin{exercise} \label{exercise 1.4.9}
Show that the matrices
\[
\begin{pmatrix}
  1 & 0 \\
  0 & 0
\end{pmatrix},
\begin{pmatrix}
  0 & 1 \\
  0 & 0
\end{pmatrix},
\begin{pmatrix}
  0 & 0 \\
  1 & 0
\end{pmatrix}, \text{ and }
\begin{pmatrix}
  0 & 0 \\
  0 & 1
\end{pmatrix}
\]
generate \(M_{2 \X 2}(F)\).
\end{exercise}

\begin{proof}
Given any \(2 \X 2\) matrix
\(A =
    \begin{pmatrix}
        a & b \\ 
        c & d
    \end{pmatrix}  
\in M_{2 \X 2}(F)\),
\(A\) can be expressed as a linear combination
\[
a \begin{pmatrix}
    1 & 0 \\
    0 & 0
\end{pmatrix}
+ b \begin{pmatrix}
    0 & 1 \\
    0 & 0
\end{pmatrix}
+ c \begin{pmatrix}
    0 & 0 \\
    1 & 0
\end{pmatrix}
+ d \begin{pmatrix}
    0 & 0 \\
    0 & 1
\end{pmatrix}
\]
Hence by \DEF{1.5}, these matrices generate \(M_{2 \X 2}(F)\).
\end{proof}

\begin{exercise} \label{exercise 1.4.10}
Show that if
\[
M_1 = \begin{pmatrix}
  1 & 0 \\
  0 & 0
\end{pmatrix},
M_2 = \begin{pmatrix}
  0 & 1 \\
  0 & 0
\end{pmatrix}, \text{ and }
M_3 = \begin{pmatrix}
  0 & 1 \\
  1 & 0
\end{pmatrix},
\]
then the span of \(\{M_1, M_2, M_3\}\) is the set of all \emph{symmetric} \(2 \X 2\) matrices.
\end{exercise}

\begin{proof}
Let \(W\) be the set of all symmetric matrices.
We have to show \(\spann(\{M_1, M_2, M_3\}) = W\).
We show this by showing \(\spann(\{M_1, M_2, M_3\}) \subseteq W\) and \(W \subseteq \spann(\{M_1, M_2, M_3\})\).

\(\spann(\{M_1, M_2, M_3\}) \subseteq W\): Suppose arbitrary \(M \in \spann(\{M_1, M_2, M_3\})\).
Then by \DEF{1.5}, \(M = a_1 M_1 + a_2 M_2 + a_3 M_3\) for some coefficients \(a_1, a_2, a_3\).
But
\begin{align*}
     & a_1 M_1 + a_2 M_2 + a_3 M_3 \\
     & = a_1 \begin{pmatrix}
            1 & 0 \\
            0 & 0
        \end{pmatrix}
        + a_2 \begin{pmatrix}
            0 & 0 \\
            0 & 1
        \end{pmatrix}
        + a_3 \begin{pmatrix}
            0 & 1 \\
            1 & 0
        \end{pmatrix} \\
    & = \begin{pmatrix}
            a_1 & 0 \\
            0 & 0
        \end{pmatrix}
        + \begin{pmatrix}
            0 & 0 \\
            0 & a_2
        \end{pmatrix}
        + \begin{pmatrix}
            0 & a_3 \\
            a_3 & 0
        \end{pmatrix} \\
    & = \begin{pmatrix}
            a_1 & a_3 \\
            a_3 & a_2
        \end{pmatrix},
\end{align*}
which is of course a symmetric matrix.
So \(M \in W\), so \(\spann(\{M_1, M_2, M_3\}) \subseteq W\).

\(W \subseteq \spann(\{M_1, M_2, M_3\})\):
Suppose arbitrary \(M \in W\).
Then \(M\) must be in the form of
\(
    \begin{pmatrix}
        a_1 & a_3 \\
        a_3 & a_2
    \end{pmatrix}
\) for some coefficients \(a_1, a_2, a_3 \in F\).
And \(M\) can be expressed as a linear combination
\[
    M = a_1 \begin{pmatrix}
            1 & 0 \\
            0 & 0
        \end{pmatrix}
        + a_2 \begin{pmatrix}
            0 & 0 \\
            0 & 1
        \end{pmatrix}
        + a_3 \begin{pmatrix}
            0 & 1 \\
            1 & 0
        \end{pmatrix}.
\]
Hence \(M \in \spann(\{M_1, M_2, M_3\})\).
So \(W \subseteq \spann(\{M_1, M_2, M_3\})\).
\end{proof}

\begin{note}
Note that in the previous exercise, we must show the two subspaces contain each other, because we do not know one of them is the whole vector space \(V\).
(If one of them is \(V\) then we can just show \(V\) is a subset of the other, since the other (subspace) is automatically a subset of \(V\).)
\end{note}

\begin{exercise} \label{exercise 1.4.11}
Prove that \(\spann(\{ x \}) = \{ ax: a \in F \}\) for any vector \(x\) in a vector space.
Interpret this result geometrically in \(\SET{R}^3\).
\end{exercise}

\begin{proof}
Suppose \(v \in \spann(\{ x \})\).
Then by \DEF{1.5}, \(v = a x\) for some coefficient \(a \in F\), hence \(v \in \{ ax: a \in F \}\).

Now suppose \(v \in \{ ax: a \in F \}\).
Then \(v = a x\) for some coefficient \(a \in F\), hence \(v\) is a linear combination of \(x\), hence \(v \in \spann(\{ x\})\).

The span is a line passing the origin in \(\SET{R}^3\), \emph{if} \(x \ne \OV\).
The span is just a zero vector space \emph{if} \(x = \OV\).
\end{proof}

\begin{exercise} \label{exercise 1.4.12}
Show that a \emph{subset} \(W\) of a vector space \(V\) \emph{is a subspace} of \(V\) if and only if \(\spann(W) = W\).
\end{exercise}

\begin{proof}
\(\Longrightarrow\): Suppose \(W\) is a subspace of \(V\), we have to show \(\spann(W) = W\).
But \(W \subseteq \spann(W)\) by \THM{1.5}(1), so we only need to show \(\spann(W) \subseteq W\).
But by \THM{1.5}(2), since \BLUE{\(W\)} is a \textbf{subspace} that (of course) contains \GREEN{\(W\)}, \BLUE{\(W\)} contains \(\spann(\GREEN{W})\).

\(\Longleftarrow\): Suppose \(W = \spann(W)\), we have to show \(W\) is a subspace of \(V\).
Well, by \THM{1.5}(1), \(\spann(W)\) is a subspace of \(V\), and \(W = \spann(W)\), so \(W\) is a subspace of \(V\).
\end{proof}

\begin{exercise} \label{exercise 1.4.13}
Show that if \(S_1\) and \(S_2\) are \emph{subsets} of a vector space \(V\) (over \(F\)) such that \(S_1 \subseteq S_2\), then \(\spann(S_1) \subseteq \spann(S_2)\).
In particular, if \(S_1 \subseteq S_2\) and \(\spann(S_1) = V\), deduce that \(\spann(S_2) = V\).
\end{exercise}

\begin{proof}
Suppose \(S_1\) and \(S_2\) are \emph{subsets} of a vector space \(V\) such that \(S_1 \subseteq S_2\).
We have to show \(\spann(S_1) \subseteq \spann(S_2)\).
So suppose arbitrary \(x \in \spann(S_1)\).
Then \(x = a_1 v_1 + a_2 v_2 + ... + a_n v_n\), where \(a_1, a_2, ..., a_n \in F\) and \(v_1, v_2, ... v_n \in S_1\).
But since \(S_1 \subseteq S_2\), \(v_1, v_2, ..., v_n \in S_2\), so \(a_1 v_1 + a_2 v_2 + ... + a_n v_n \in \spann(S_2)\);
that is, \(x \in \spann(S_2)\).
Since \(x\) is arbitrary, \(\spann(S_1) \subseteq \spann(S_2)\), as desired.

In particular, suppose \(S_1 \subseteq S_2\) and \(\spann(S_1) = V\).
By previous case we have \(\spann(S_1) \subseteq \spann(S_2)\);
that is, \(V \subseteq \spann(S_2)\).
But since \(\spann(S_2)\) is just a subspace of \(V\), in particular it is a subset of \(V\), so \(\spann(S_2) \subseteq V\).
So together we have \(\spann(S_2) = V\).
\end{proof}

\begin{exercise} \label{exercise 1.4.14}
Show that if \(S_1\) and \(S_2\) are arbitrary subsets of a vector space \(V\) (over \(F\)), then \(\spann(S_1 \cup S_2) = \spann(S_1) + \spann(S_2)\), where the sum uses \ADEF{1.8}.
\end{exercise}

\begin{proof}
Given any vector space \(V\), let \(S_1\) and \(S_2\) be arbitrary subsets of \(V\).
We have to show \(\spann(S_1 \cup S_2) = \spann(S_1) + \spann(S_2)\).

\BLUE{\(\spann(S_1 \cup S_2) \subseteq \spann(S_1) + \spann(S_2)\)}:
Suppose \(x \in \spann(S_1 \cup S_2)\).
Then
\[
    x = a_1 v_1 + a_2 v_2 + ... + a_n v_n + b_1 u_1 + b_2 u_2 + ... + b_m u_m,
\]
where \(a_1, a_2, ..., a_n, b_1, b_2, ... b_m \in F\), \(v_1, v_2, ..., v_n \in S_1\), and \(u_1, u_2, ..., u_m \in S_2\).
But that implies
\begin{align*}
    x & = (a_1 v_1 + a_2 v_2 + ... + a_n v_n) \\
      & + (b_1 u_1 + b_2 u_2 + ... + b_m u_m),
\end{align*}
where by \DEF{1.4} \(a_1 v_1 + a_2 v_2 + ... + a_n v_n \in \spann(S_1)\) and \(b_1 u_1 + b_2 u_2 + ... + b_m u_m \in \spann(S_2)\).
And by definition of \(\spann(S_1) + \spann(S_2)\), \(x \in \spann(S_1) + \spann(S_2)\).
Since \(x\) is arbitrary, \(\spann(S_1 \cup S_2) \subseteq \spann(S_1) + \spann(S_2)\).

\BLUE{\(\spann(S_1) + \spann(S_2) \subseteq \spann(S_1 \cup S_2)\)}:
Suppose \(x \in \spann(S_1) + \spann(S_2)\).
Then \(x = v + u\) where \(v \in \spann(S_1)\) and \(u \in \spann(S_2)\).
And by \DEF{1.5}, \(v = a_1 v_1 + a_2 v_2 + ... + a_n v_n\) and \(u = b_1 u_2 + b_2 u_2 + ... + b_m u_m\), where \(a_1, ..., a_n, b_1, ..., b_m \in F\), \(v_1, ..., v_n \in S_1\) and \(u_1, ..., u_m \in S_2\).
So we have \(x = v + u = (a_1 v_1 + a_2 v_2 + ... + a_n) + (b_1 u_2 + b_2 u_2 + ... + b_m u_m)\), where \(v_1, ..., v_n, u_1, ..., u_m \in S_1 \cup S_2\).
Then by \DEF{1.4} again, \(x \in \spann(S_1 \cup S_2)\).
Since \(x\) is arbitrary, \(\spann(S_1) + \spann(S_2) \subseteq \spann(S_1 \cup S_2)\).
\end{proof}

\begin{exercise} \label{exercise 1.4.15}
Let \(S_1\) and \(S_2\) be subsets of a vector space \(V\) (over \(F\)).
Prove that \(\spann(S_1 \cap S_2) \subseteq \spann(S_1) \cap \spann(S_2)\).
Give an example in which \(\spann(S1 \cap S_2)\) and
\(\spann(S_1) \cap \spann(S_2)\) are equal and one in which they are unequal.
\end{exercise}

\begin{proof}
So suppose arbitrary \(x \in \spann(S_1 \cap S_2)\).
By \DEF{1.4}, \(x = a_1 v_1 + ... + a_n v_n\), where \(a_1, ..., a_n \in F\), and \(v_1, v_2, ..., v_n \in S_1 \cap S_2\).
In particular, \(v_1, v_2, ..., v_n \in S_1\) and \(v_1, v_2, ..., v_n \in S_2\).
So again by \DEF{1.4}, \(a_1 v_1 + ... + a_n v_n \in \spann(S_1)\) and \(a_1 v_1 + ... + a_n v_n \in \spann(S_2)\).
That is, \(x \in \spann(S_1)\) and \(x \in \spann(S_2)\).
In particular, \(x \in \spann(S_1) \cap \spann(S_2)\).
Since \(x\) is arbitrary, \(\spann(S_1 \cap S_2) \subseteq \spann(S_1) \cap \spann(S_2)\).

Now for the case of \(\spann(S1 \cap S_2) = \spann(S_1) \cap \spann(S_2)\), just let \(S_1 = S_2\):
\begin{align*}
    & \spann(S_1 \cap S_2) \\
    & = \spann(S_1 \cap S_1) \\
    & = \spann(S_1) & \text{since of course \(S_1 \cap S_1 = S_1\)} \\
    & = \spann(S_1) \cap \spann(S_1) & \text{since of course \(\spann(S_1) = \spann(S_1) \cap \spann(S_1)\)}
\end{align*}
For the case of \(\spann(S1 \cap S_2) \ne \spann(S_1) \cap \spann(S_2)\), let \(V = \SET{R}^2\), \(S_1 = \{(1, 0), (0, 1)\}\), \(S_2 = \{(-1, )\}\).
Then it's trivial that \(\spann(S_1 = R^2\), \(\spann(S_2)\) is \(x\)-axis, so the intersection is also \(x\)-axis.
But \(S_1 \cap \S_2 = \emptyset\), so \(\spann(S_1 \cap S_2) = \{ (0, 0) \}\) by \DEF{1.4}.
So \(\spann(S_1 \cap S_2) = \{ (0, 0) \}\), which does not equal to \(\spann(S_1) \cap \spann(S_2)\), the \(x\)-axis.
\end{proof}

\begin{exercise} \label{exercise 1.4.16}
Let \(V\) be a vector space (over \(F\)) and \(S\) a subset of \(V\) with the property that whenever \(v_1, v_2, ..., v_n \in S\) and \(a_1 v_1 + a_2 v_2 + ... + a_n v_n = \OV\), then \(a_1 = a_2 = ... = a_n = \OF\).
Prove that every vector in the span of \(S\) can be \textbf{uniquely written} as a linear combination of vectors of \(S\).
\end{exercise}

\begin{note}
\EXEC{1.4.16} is related to the concept of \textbf{linear independence}; see \SEC{1.5}.
\end{note}

\begin{proof}
Suppose arbitrary \(v \in \spann(S)\) s.t.
\[
    v = a_1 v_1 + a_2 v_2 + ... + a_n v_n
\]
and
\[
    v = b_1 v_1 + b_2 v_2 + ... + b_n v_n,
\]
where \(a_1, ..., a_n, b_1, ..., b_n \in F\) and \(v_1, ..., v_2 \in S\).
Then we have
\begin{align*}
    0 = v + (-v) & = a_1 v_1 + a_2 v_2 + ... + a_n v_n + -(b_1 v_1 + b_2 v_2 + ... + b_n v_n) \\
                 & = (a_1 - b_1) v_1 + (a_2 - b_2) v_2 + ... + (a_n - b_n) v_n.
\end{align*}
But by the supposition of the property of \(S\), we have \(a_1 - b_1 = a_2 - b_2 = ... = a_n - b_n = \OF\).
That is, \(a_1 = b_1, a_2 = b_2, ..., a_n = b_n\).
So any \(v \in \spann(S)\), can only uniquely be written as a linear combination of vectors of \(S\).
\end{proof}

\begin{exercise} \label{exercise 1.4.17}
Let \(W\) be a subspace of a vector space \(V\).
Under what conditions are there only a finite number of distinct subsets \(S\) of \(W\) such that \(S\) generates \(W\)?
\end{exercise}

\begin{proof}
We claim that \(W\) can only have finite elements. (and \(F\) has characteristic zero, see textbook page 549.)

If \(W\) has finite elements, then by set theory the number of distinct subsets of \(W\) is also finite;
in particular, the number of subsets of \(W\) that can generate \(W\) is also finite.

But if \(W\) has infinite elements, and suppose \(S = \{v_1, v_2, ..., v_n\}\) generates \(W\);
then in particular it's trivial that \(\{a v_1, a v_2, ..., a v_n\}\) also generates \(W\) for any \emph{nonzero} \(a \in F\).
Since we can find infinite \(a \in F\)(since \(F\) has characteristic zero), the number of subset of \(W\) that can generate \(W\) is also infinite.
\end{proof}

\begin{additional theorem} \label{athm 1.11}
This is the placeholder theorem for \EXEC{1.4.12}: The span of a subspace is equal to that subspace.
\end{additional theorem}

\begin{additional theorem} \label{athm 1.12}
This is the placeholder theorem for \EXEC{1.4.13}:

\BLUE{(1)} Set inclusion implies span inclusion.

\BLUE{(2)}: If the span of smaller set is already equal to \(V\), then the span of bigger set is also equal to \(V\).
\end{additional theorem}

\begin{additional theorem} \label{athm 1.13}
This is the placeholder theorem for \EXEC{1.4.14}:
\(\spann(S_1 \cup S_2) = \spann(S_1) + \spann(S_2)\).
\end{additional theorem}

\begin{additional theorem} \label{athm 1.14}
This is the placeholder theorem for \EXEC{1.4.15}: \(\spann(S_1 \cap S_2) \subseteq \spann(S_1) \cap \spann(S_2)\).
\end{additional theorem}
